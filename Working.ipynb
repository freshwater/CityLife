{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyspark as ps\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "response_cache = {}\n",
    "\n",
    "def http_get(url):\n",
    "    if response := response_cache.get(url):\n",
    "        return response\n",
    "    else:\n",
    "        response = requests.request(url=url, method=\"GET\")\n",
    "        counties_list_html = response.content\n",
    "        response_cache[url] = counties_list_html\n",
    "        \n",
    "        return response_cache[url]\n",
    "\n",
    "spark = (ps.sql.SparkSession\n",
    "         .builder\n",
    "         .master('local[8]')\n",
    "         .appName('lecture')\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia_export_get(title):\n",
    "    xml = http_get(\"https://en.wikipedia.org/wiki/Special:Export/\" + title)\n",
    "    \n",
    "    if b'<redirect title' in xml:\n",
    "        return wikipedia_export_get(title=BeautifulSoup(xml).select('redirect')[0]['title'])\n",
    "    else:\n",
    "        return xml\n",
    "\n",
    "def wikipedia_standard_url(title):\n",
    "    return \"https://en.wikipedia.org/wiki/\" + title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cities_all = (sc.textFile('communities_all.txt')\n",
    "                .map(wikipedia_export_get)\n",
    "                # .map(lambda export: BeautifulSoup(export).select('text')[0].getText())\n",
    "                .cache())\n",
    "\n",
    "cities_all.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_all = (counties_export_text.map(wikipedia_communities_extract)\n",
    "                                       .filter(lambda x: x != [])\n",
    "                                       .map(lambda x: x[1]))\n",
    "\n",
    "# out = [o for o in out if o[0] == tuple() and ',_Indiana' in o[1]]\n",
    "# out = [o for o in out if o[0] != tuple() and ',_Puerto_Rico' not in o[1]]\n",
    "# out = [o for o in out if o[0] != tuple() and ',_Indiana' in o[1]]\n",
    "# out = [o for o in out if o[0] != tuple() and ',_Virginia' in o[1]]\n",
    "# out = [o for o in out if o[0] != tuple() and ',_Alaska' in o[1]]\n",
    "\n",
    "communities_all_1 = list(communities_all.map(set).reduce(set.union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<br>'.join([f'<a href=\"{wikipedia_standard_url(title)}\">{title}</a>' for title in np.random.choice(communities_all_1, 250)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Newtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1(x):\n",
    "    with open('communities_all.txt') as f:\n",
    "        return len(f.readlines()) + x\n",
    "\n",
    "sc.parallelize(range(105)).map(test_1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BeautifulSoup(wikipedia_export_get(np.random.choice(communities_all_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
